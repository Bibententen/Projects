{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a106c2-f185-492f-87bb-79286c2eacc4",
   "metadata": {},
   "source": [
    "### __BUSA8001 Group Assignment - Predicting Airbnb Listing Prices in Melbourne__ {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c316658-edf7-4797-b078-202987b4922b",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Kaggle Competition Ends:** Friday, 4 November 2022 @ 3:00pm (Week 13)  \n",
    "**Assignment Due Date on iLearn:** Friday, 4 November 2022 @ 11.59pm (Week 13)   \n",
    "\n",
    "**Overview:**   \n",
    "\n",
    "- In the group assignment you will form a team of up to 3 students (minimum 2) and participate in a forecasting competition on Kaggle\n",
    "- The goal is to predict listed prices of Airbnb properties in Melbourne based on various Airbnb characteristics and regression models\n",
    "\n",
    "- You will:  \n",
    "    - Write a problem statement and perform Exploratory Data Analysis  \n",
    "    - Clean up data, deal with categorical features and missing observations, and create new variables (feature engineering)  \n",
    "    - Construct and tune forecasting models, produce forecasts and submit your predictions to Kaggle  \n",
    "    - Each member of the team will record a video presentation of their work  \n",
    "    - Marks will be awarded producing a prediction in the top 5 positions of their unit as well as for reaching the highest ranking on Kaggle amongst all teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2270744-5e12-447b-a861-9719409e287c",
   "metadata": {},
   "source": [
    "**Instructions:** \n",
    "\n",
    "- Form a team of 3 students (minimum 2 students)  \n",
    "- Each team member needs to join [https://www.kaggle.com](https://www.kaggle.com/)  \n",
    "- Choose a team leader and form a team in the competition [https://www.kaggle.com/t/0854c07cc3ac4037920a9fa4cdebacd1](https://www.kaggle.com/t/0854c07cc3ac4037920a9fa4cdebacd1)\n",
    "    - Team leader to click on `team` and join and invite other team members to join\n",
    "    - Your **team's name must start** with your unit code, for instance you could have a team called BUSA8001_masterful_geniuses \n",
    "- All team members should work on all the tasks listed below however   \n",
    "    - **Choose a team member who will be responsible for one of each of the 3 tasks listed below**    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ee56b-c5b9-4078-8754-e04f90797514",
   "metadata": {},
   "source": [
    "**Marks**: \n",
    "\n",
    "- Total Marks: 40\n",
    "- Your individual mark will consist of:  \n",
    "    - 50% x overall assignment mark + 45% x mark for the task that you are responsible for + 5% x mark received from your teammates for your effort in group work \n",
    "- 7 marks will be deducted from each Task for which there is no video presentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f70e4c-b794-4555-b170-d80b628b2904",
   "metadata": {},
   "source": [
    "**Competition Marks:**  \n",
    "\n",
    "- 2 marks: Ranking in the top 5 places of your unit on Kaggle (make sure you name your team as instructed above)   \n",
    "- 2 marks: Reaching the first place in your unit  (make sure you name your team as instructed above)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3180e9-c3cc-494c-ae64-d3b9701e10e8",
   "metadata": {},
   "source": [
    "\n",
    "**Submissions:**  \n",
    "\n",
    "1. On Kaggle: submit your team's forecast in order to be ranked by Kaggle\n",
    "    - Can do this as many times as necessary while building their model  \n",
    "2. On iLearn **only team leader to submit** this Jupyter notebook re-named `Group_Assignment_Team_Name.ipynb` where Team_Name is your team's name on Kaggle   \n",
    "    - The Jupyter notebook must contain team members names/ID numbers, and team name in the competition\n",
    "    - Provide answers to the 3 Tasks below in the allocated cells including all codes/outputs/writeups \n",
    "    - One 15 minute video recording of your work \n",
    "        - Each team member to provide a 5 minute presentation of the Task that they led (it is best to jointly record your video using Zoom)\n",
    "        - When recording your video make sure your face is visible, that you share your Jupyter Notebook and explain everything you've done in the submitted Jupyter notebook on screen\n",
    "        - 7 marks will be deducted from each Task for which there is no video presentation or if you don't follow the above instructions\n",
    "        \n",
    "3. On iLearn each student needs to submit a file with their teammates' names, ID number and a mark for their group effort (out of 100%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbce8a-bf4f-4155-9336-6367fd239f6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe68a60-5e8b-4c4e-b562-3a82fa426395",
   "metadata": {},
   "source": [
    "**Fill out the following information**\n",
    "\n",
    "For each team member provide name, Student ID number and which task is performed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac487d3-755a-4a69-a22f-d599dbdd7979",
   "metadata": {},
   "source": [
    "- Team Name on Kaggle: `BUSA8001_Team 1`\n",
    "- Team Leader and Team Member 1: `Duy Pham - 47522003 - Task 2`\n",
    "- Team Member 2: `Thi Kim Ngan Do - 46235752 - Task 1`\n",
    "- Team Member 3: `Ahsan Adil Nibir - 44397836 - Task 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24de689-928d-4991-b337-760c12780e5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Problem Description and Initial Data Analysis {-}\n",
    "\n",
    "1. Read the Competition Overview on Kaggle [https://www.kaggle.com/t/0854c07cc3ac4037920a9fa4cdebacd1](https://www.kaggle.com/t/0854c07cc3ac4037920a9fa4cdebacd1)\n",
    "2. Referring to Competition Overview and the data provided on Kaggle write about a 500 words **Problem Description** focusing on key points that will need to be addressed as first steps in Tasks 2 and 3 below, using the following headings:\n",
    "    - Forecasting Problem\n",
    "    - Evaluation Criteria\n",
    "    - Types of Variables/Features\n",
    "    - Data summary and main data characteristics\n",
    "    - Missing Values (only explain what you found at this stage)\n",
    "    - Note: you should **not** discuss any specific predictive algorithms at this stage.\n",
    "    \n",
    "Total Marks: 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48498ac-6f81-4259-a177-20ce56fe7a55",
   "metadata": {},
   "source": [
    "The Problem: Currently there is no convenient way for a new Airbnb host to decide the price of his or her listing. New hosts must often rely on the price of neighbouring listings when deciding on the price of their own listing.\n",
    "\n",
    "Our project aims at predicting Airbnb listing prices for Melbourne based on the characteristics of listed properties to help hosts decide reasonable price. A Predictive Price Modelling tool whereby a new host can enter all the relevant details such as location of the listing, listing properties, available amenities etc and the Machine Learning Model will suggest the Price for the listing. We will train and make comparisons between different methods. \n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "In this project, we will employ MSE to evaluate the performance of the linear regression model, Decision Trees and Random Forests.\n",
    "The Mean Squared Error (MSE) is the average of the summation of the squared difference between the estimated values and actual values. It is an important to reduce the value of MSE in evaluating the performance of machine learning models. \n",
    "\n",
    "$MSE=\\frac{1}{n}\\sum_{i=1}^n\\left(y_{i} - \\hat{y}_{i}\\right)^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcfd49e-fcbb-4eaa-936b-144b574495d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: (7000, 62)\n",
      "df_test: (3000, 61)\n",
      "df: (10000, 62)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ord_enc = OrdinalEncoder()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_submit= pd.read_csv('sample_submission.csv') #load submission sample\n",
    "df_train = pd.read_csv('train.csv') # load train dataset\n",
    "df_test = pd.read_csv('test.csv') # load test dataset\n",
    "\n",
    "df_test['type'] = \"test\"\n",
    "df_train['type'] = \"train\"\n",
    "\n",
    "df = pd.concat([df_test, df_train])\n",
    "\n",
    "print('df_train:',df_train.shape)\n",
    "print('df_test:',df_test.shape)\n",
    "print('df:',df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffefcc8-301b-496c-9186-654f63e9391b",
   "metadata": {},
   "source": [
    "Dataset provided are divided into training data (7000 observations) and test data (3000 observations) separately. Training data consists of 7000 entries and 61 variables, while test dataset contains 3000 observations and 60 variables and the target variable is price that we will predict later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65528211-51a5-42d9-b065-6fcc76689b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 6999\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   ID                                            10000 non-null  int64  \n",
      " 1   source                                        10000 non-null  object \n",
      " 2   name                                          9999 non-null   object \n",
      " 3   description                                   9924 non-null   object \n",
      " 4   neighborhood_overview                         6739 non-null   object \n",
      " 5   host_name                                     10000 non-null  object \n",
      " 6   host_since                                    10000 non-null  object \n",
      " 7   host_location                                 7924 non-null   object \n",
      " 8   host_about                                    6269 non-null   object \n",
      " 9   host_response_time                            9612 non-null   object \n",
      " 10  host_response_rate                            9612 non-null   object \n",
      " 11  host_acceptance_rate                          9609 non-null   object \n",
      " 12  host_is_superhost                             10000 non-null  object \n",
      " 13  host_neighbourhood                            4446 non-null   object \n",
      " 14  host_listings_count                           10000 non-null  float64\n",
      " 15  host_verifications                            10000 non-null  object \n",
      " 16  host_has_profile_pic                          10000 non-null  object \n",
      " 17  host_identity_verified                        10000 non-null  object \n",
      " 18  neighbourhood                                 6739 non-null   object \n",
      " 19  neighbourhood_cleansed                        9850 non-null   object \n",
      " 20  latitude                                      10000 non-null  float64\n",
      " 21  longitude                                     10000 non-null  float64\n",
      " 22  property_type                                 9877 non-null   object \n",
      " 23  room_type                                     9825 non-null   object \n",
      " 24  accommodates                                  10000 non-null  int64  \n",
      " 25  bathrooms                                     9990 non-null   object \n",
      " 26  bedrooms                                      9560 non-null   float64\n",
      " 27  beds                                          9903 non-null   float64\n",
      " 28  amenities                                     10000 non-null  object \n",
      " 29  minimum_nights                                10000 non-null  int64  \n",
      " 30  maximum_nights                                10000 non-null  int64  \n",
      " 31  minimum_minimum_nights                        9945 non-null   float64\n",
      " 32  maximum_minimum_nights                        10000 non-null  int64  \n",
      " 33  minimum_maximum_nights                        10000 non-null  int64  \n",
      " 34  maximum_maximum_nights                        9945 non-null   float64\n",
      " 35  minimum_nights_avg_ntm                        10000 non-null  float64\n",
      " 36  maximum_nights_avg_ntm                        10000 non-null  float64\n",
      " 37  has_availability                              10000 non-null  object \n",
      " 38  availability_30                               10000 non-null  int64  \n",
      " 39  availability_60                               10000 non-null  int64  \n",
      " 40  availability_90                               10000 non-null  int64  \n",
      " 41  availability_365                              9933 non-null   float64\n",
      " 42  number_of_reviews                             10000 non-null  int64  \n",
      " 43  number_of_reviews_ltm                         10000 non-null  int64  \n",
      " 44  number_of_reviews_l30d                        10000 non-null  int64  \n",
      " 45  first_review                                  9877 non-null   object \n",
      " 46  last_review                                   9877 non-null   object \n",
      " 47  review_scores_rating                          9877 non-null   float64\n",
      " 48  review_scores_accuracy                        9831 non-null   float64\n",
      " 49  review_scores_cleanliness                     9831 non-null   float64\n",
      " 50  review_scores_checkin                         9831 non-null   float64\n",
      " 51  review_scores_communication                   9832 non-null   float64\n",
      " 52  review_scores_location                        9831 non-null   float64\n",
      " 53  review_scores_value                           9831 non-null   float64\n",
      " 54  instant_bookable                              10000 non-null  object \n",
      " 55  calculated_host_listings_count                10000 non-null  int64  \n",
      " 56  calculated_host_listings_count_entire_homes   10000 non-null  int64  \n",
      " 57  calculated_host_listings_count_private_rooms  10000 non-null  int64  \n",
      " 58  calculated_host_listings_count_shared_rooms   10000 non-null  int64  \n",
      " 59  reviews_per_month                             9877 non-null   float64\n",
      " 60  type                                          10000 non-null  object \n",
      " 61  price                                         7000 non-null   object \n",
      "dtypes: float64(18), int64(16), object(28)\n",
      "memory usage: 4.8+ MB\n",
      "df.info()\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print('df.info()\\n',df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628e443-022c-4d5a-b8fb-90ca421ca742",
   "metadata": {},
   "source": [
    "int64, float64 and object are the data types of our features. Here we found that there are 27 variables which are object or string, 34 features are numeric. Then we need to convert that string to the integer data only. There are 4 types of features:\n",
    "-\tNumerical variables: accommodates, bathrooms, bedrooms, beds minimum_nights, maximum_nights, minimum_minimum_nights, maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights, maximum_nights_avg_ntm, availability_30, availability_60, availability_90, number_of_reviews, number_of_reviews_ltm, number_of_reviews_l30d, review_scores_rating, review_scores_accuracy,etc.\n",
    "-\tNominal categorical variables: host_response_time ,host_verifications, Private room in home, room_type, bathroom, bedrooms\t\n",
    "-\tBinary categorical variables (True /False): sort, host_is_superhost , host_has_profile_pic, host_identity_verified, has_availability, instant_bookable\t\n",
    "-\tDate: first_review, last_review, host_since\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a1da4c-388e-4f6e-9e99-3948e9776481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_neighbourhood             5554\n",
       "host_about                     3731\n",
       "neighborhood_overview          3261\n",
       "neighbourhood                  3261\n",
       "price                          3000\n",
       "host_location                  2076\n",
       "bedrooms                        440\n",
       "host_acceptance_rate            391\n",
       "host_response_time              388\n",
       "host_response_rate              388\n",
       "room_type                       175\n",
       "review_scores_checkin           169\n",
       "review_scores_location          169\n",
       "review_scores_cleanliness       169\n",
       "review_scores_value             169\n",
       "review_scores_accuracy          169\n",
       "review_scores_communication     168\n",
       "neighbourhood_cleansed          150\n",
       "review_scores_rating            123\n",
       "reviews_per_month               123\n",
       "last_review                     123\n",
       "first_review                    123\n",
       "property_type                   123\n",
       "beds                             97\n",
       "description                      76\n",
       "availability_365                 67\n",
       "maximum_maximum_nights           55\n",
       "minimum_minimum_nights           55\n",
       "bathrooms                        10\n",
       "name                              1\n",
       "amenities                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isnull().sum().sort_values(ascending = False).head(31)                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748dcd53-fed9-4ff5-8838-f44071095697",
   "metadata": {},
   "source": [
    "As we can see, there are 30 variables containing null values that we need to clean in the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf8c44-bd19-4a8e-8d73-26cf05c684f7",
   "metadata": {},
   "source": [
    "Main data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34bf44ed-ef8e-4ffd-969b-1b39a92a89dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.5</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2499.75</td>\n",
       "      <td>4999.5</td>\n",
       "      <td>7499.25</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>city scrape</td>\n",
       "      <td>8940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>9999</td>\n",
       "      <td>9746</td>\n",
       "      <td>墨尔本东北区Bundoora温馨独栋别墅，房间干净整齐、设施齐全、交通方便、高速网络、高档床...</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>9924</td>\n",
       "      <td>9391</td>\n",
       "      <td>Rise and shine with the best of Melbourne on y...</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>6739</td>\n",
       "      <td>5641</td>\n",
       "      <td>Melbourne - Voted most livable city in the wor...</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2876</td>\n",
       "      <td>21.001919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.409139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>9877.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.585362</td>\n",
       "      <td>1.791966</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.19</td>\n",
       "      <td>49.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>7000</td>\n",
       "      <td>683</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                count unique  \\\n",
       "ID                                            10000.0    NaN   \n",
       "source                                          10000      2   \n",
       "name                                             9999   9746   \n",
       "description                                      9924   9391   \n",
       "neighborhood_overview                            6739   5641   \n",
       "...                                               ...    ...   \n",
       "calculated_host_listings_count_private_rooms  10000.0    NaN   \n",
       "calculated_host_listings_count_shared_rooms   10000.0    NaN   \n",
       "reviews_per_month                              9877.0    NaN   \n",
       "type                                            10000      2   \n",
       "price                                            7000    683   \n",
       "\n",
       "                                                                                            top  \\\n",
       "ID                                                                                          NaN   \n",
       "source                                                                              city scrape   \n",
       "name                                          墨尔本东北区Bundoora温馨独栋别墅，房间干净整齐、设施齐全、交通方便、高速网络、高档床...   \n",
       "description                                   Rise and shine with the best of Melbourne on y...   \n",
       "neighborhood_overview                         Melbourne - Voted most livable city in the wor...   \n",
       "...                                                                                         ...   \n",
       "calculated_host_listings_count_private_rooms                                                NaN   \n",
       "calculated_host_listings_count_shared_rooms                                                 NaN   \n",
       "reviews_per_month                                                                           NaN   \n",
       "type                                                                                      train   \n",
       "price                                                                                   $120.00   \n",
       "\n",
       "                                              freq      mean         std  \\\n",
       "ID                                             NaN    4999.5  2886.89568   \n",
       "source                                        8940       NaN         NaN   \n",
       "name                                            13       NaN         NaN   \n",
       "description                                     18       NaN         NaN   \n",
       "neighborhood_overview                           33       NaN         NaN   \n",
       "...                                            ...       ...         ...   \n",
       "calculated_host_listings_count_private_rooms   NaN    3.2876   21.001919   \n",
       "calculated_host_listings_count_shared_rooms    NaN    0.0335    0.409139   \n",
       "reviews_per_month                              NaN  1.585362    1.791966   \n",
       "type                                          7000       NaN         NaN   \n",
       "price                                          130       NaN         NaN   \n",
       "\n",
       "                                               min      25%     50%      75%  \\\n",
       "ID                                             0.0  2499.75  4999.5  7499.25   \n",
       "source                                         NaN      NaN     NaN      NaN   \n",
       "name                                           NaN      NaN     NaN      NaN   \n",
       "description                                    NaN      NaN     NaN      NaN   \n",
       "neighborhood_overview                          NaN      NaN     NaN      NaN   \n",
       "...                                            ...      ...     ...      ...   \n",
       "calculated_host_listings_count_private_rooms   0.0      0.0     0.0      1.0   \n",
       "calculated_host_listings_count_shared_rooms    0.0      0.0     0.0      0.0   \n",
       "reviews_per_month                             0.01     0.42    1.05     2.19   \n",
       "type                                           NaN      NaN     NaN      NaN   \n",
       "price                                          NaN      NaN     NaN      NaN   \n",
       "\n",
       "                                                 max  \n",
       "ID                                            9999.0  \n",
       "source                                           NaN  \n",
       "name                                             NaN  \n",
       "description                                      NaN  \n",
       "neighborhood_overview                            NaN  \n",
       "...                                              ...  \n",
       "calculated_host_listings_count_private_rooms   168.0  \n",
       "calculated_host_listings_count_shared_rooms     13.0  \n",
       "reviews_per_month                              49.27  \n",
       "type                                             NaN  \n",
       "price                                            NaN  \n",
       "\n",
       "[62 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e655f-9b4e-4535-83d0-a523d39af63e",
   "metadata": {
    "tags": []
   },
   "source": [
    "From this table, we get the summary of the categorical variables:\n",
    "-\t' count' which count the number of non-missing values. For example, ‘name’ variable is missing 1 value\n",
    "-\t‘unique’ (number of unique values): eg.  There are 5641 unique values in neighborhood_overview. The remainings are duplicated.\n",
    "-\t‘top’ (the most frequent value), and the frequency of the most frequent value. As we can observe from the table, the most popular price for Airbnb is 120$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd52df8-d6da-4cd6-aa3c-34d5ea681974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7960bb55-92da-4528-9ee1-e06e46f00cae",
   "metadata": {},
   "source": [
    "`(Task 1, Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30df24-b18b-4f61-975f-ceebe2e2c3ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Data Cleaning, Missing Observations and Feature Engineering {-}\n",
    "- In this task you will follow a set of instructions/questions listed below.\n",
    "- Make sure you **explain** each step you do both in Markdown text and on your video.\n",
    "    - Do not just read out your commands without exaplaining what they do and why you used them \n",
    "\n",
    "Total Marks: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4ec3d-4936-4428-a204-04f133210a3d",
   "metadata": {},
   "source": [
    "**Task 2, Question 1**: Clean **all** numerical features and the target variable `price` so that they can be used in training algorithms. For instance, `host_response_rate` feature is in object format containing both numerical values and text. Extract numerical values (or equivalently eliminate the text) so that the numerical values can be used as a regular feature.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32485e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 1 Code Here\n",
    "\n",
    "# clean price column in train dataset\n",
    "df['price'] = df['price'].str.replace('$', '')\n",
    "df['price'] = df['price'].str.replace(',', '')\n",
    "\n",
    "# clean 'host_response_rate'\n",
    "df['host_response_rate'] = df['host_response_rate'].str.replace('%', '') # eliminate text\n",
    "df['host_response_rate'] = df['host_response_rate'].astype('float') # change datatype to float\n",
    "\n",
    "# clean 'host_acceptance_rate'\n",
    "df['host_acceptance_rate'] = df['host_acceptance_rate'].str.replace('%', '')\n",
    "df['host_acceptance_rate'] = df['host_acceptance_rate'].astype('float')\n",
    "\n",
    "# clean 'host_verifications'\n",
    "df['host_verifications'] = df['host_verifications'].str.replace('[', '')\n",
    "df['host_verifications'] = df['host_verifications'].str.replace(']', '')\n",
    "df['host_verifications'] = df['host_verifications'].str.replace(\"'\", '')\n",
    "\n",
    "# clean 'host_verifications'\n",
    "\n",
    "df['Neighbour'] = df['neighbourhood'].str.split(' ').str[0] #make Neighbour column from the existing neighbourhood\n",
    "df['Neighbour'] = df['Neighbour'].str.replace(\",\", '')\n",
    "\n",
    "# bathrooms\n",
    "\n",
    "#clean text\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('Half-bath','0.5')\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('Shared half-bath','0.5')\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('Private half-bath','0.5')\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('baths','')\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('bath','')\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('shared','')\n",
    "df['bathrooms'] = df['bathrooms'].str.replace('private','')\n",
    "df['bathrooms'] = df['bathrooms'].astype('float') # change data type\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313fef0-4043-4c03-8f3f-4691b5f61f11",
   "metadata": {},
   "source": [
    "`(Task 2, Question 1 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f1bb1",
   "metadata": {},
   "source": [
    "**Task 2, Question 2** Create at least 4 new features from existing features which contain multiple items of information, e.g. creating `email`,  `phone`, `work_email`, etc. from feature `host_verifications`.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d210de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 2 Code Here\n",
    "\n",
    "# host_since \n",
    "df['host_since'] =(pd.Timestamp.now()- pd.to_datetime(df['host_since'], dayfirst=True)).dt.days # count day until now\n",
    "\n",
    "# host_verifications\n",
    "\n",
    "dummy_host_verifications = df['host_verifications'].str.get_dummies(', ') # split host_verification into email,phone,work_email columns\n",
    "df = pd.concat([df, dummy_host_verifications], axis = 1) # join columns into dataframe\n",
    "\n",
    "# host_location \n",
    "\n",
    "df[['City', 'Country']] = df['host_location'].str.split(', ', 1, expand=True) # split host location to city and country\n",
    "df['Country'].fillna('Other Country', inplace = True) # fill na with Australia\n",
    "df['Country'][df['Country']!= 'Australia']= 'Other Country' # Change other country to 'Other Country'\n",
    "df['City'].fillna('Other City', inplace = True) # fill NA with 'Other City'\n",
    "df['City'] = df['City'].where(df['Country'] !='Other Country','Other City') # for city in other countries, change to 'Other City'\n",
    "\n",
    "# neighbourhood\n",
    "\n",
    "df['Neighbour'] = df['neighbourhood'].str.split(' ').str[0] #make Neighbour column from the existing neighbourhood\n",
    "df['Neighbour'] = df['Neighbour'].str.replace(\",\", '') \n",
    "\n",
    "# first_review\n",
    "\n",
    "df['first_review'] =(pd.Timestamp.now()- pd.to_datetime(df['first_review'], dayfirst=True)).dt.days # count day until now\n",
    "\n",
    "# last_review\n",
    "\n",
    "df['last_review'] =(pd.Timestamp.now()- pd.to_datetime(df['last_review'], dayfirst=True)).dt.days # count day until now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fde9b6-bed0-4018-9edb-3553f3d1fa13",
   "metadata": {},
   "source": [
    "`(Task 2, Question 2 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01c4d-1412-4e51-8f80-7040f536b1c7",
   "metadata": {},
   "source": [
    "**Task 2, Question 3**: Impute missing values for all features in both training and test datasets.   \n",
    "(3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36412d68-f68f-4764-aa6f-88ba33116ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 3 Code Here\n",
    "\n",
    "df['host_response_rate'].fillna(df['host_response_rate'].mean(), inplace = True)\n",
    "\n",
    "df['host_acceptance_rate'].fillna(df['host_acceptance_rate'].mean(), inplace = True)\n",
    "\n",
    "room_type_list = df['room_type'].value_counts().index.tolist() \n",
    "df.loc[df['room_type'].isin(room_type_list) == False, 'room_type'] = df['room_type'].mode()[0] # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "bathrooms_list = df['bathrooms'].value_counts().index.tolist() \n",
    "df.loc[df['bathrooms'].isin(bathrooms_list) == False, 'bathrooms'] = df['bathrooms'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "bedrooms_list = df['bedrooms'].value_counts().index.tolist() \n",
    "df.loc[df['bedrooms'].isin(bedrooms_list) == False, 'bedrooms'] = df['bedrooms'].median() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "beds_list = df['beds'].value_counts().index.tolist() \n",
    "df.loc[df['beds'].isin(beds_list) == False, 'beds'] = df['beds'].median() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "df['minimum_nights'].fillna(df['minimum_nights'].median(), inplace = True)\n",
    "\n",
    "df['maximum_nights'].fillna(df['maximum_nights'].mean(), inplace = True)\n",
    "\n",
    "minimum_minimum_nights_list = df['minimum_minimum_nights'].value_counts().index.tolist() \n",
    "df.loc[df['minimum_minimum_nights'].isin(minimum_minimum_nights_list) == False, 'minimum_minimum_nights'] = df['minimum_minimum_nights'].median() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "maximum_maximum_nights_list = df['maximum_maximum_nights'].value_counts().index.tolist() \n",
    "df.loc[df['maximum_maximum_nights'].isin(maximum_maximum_nights_list) == False, 'maximum_maximum_nights'] = df['maximum_maximum_nights'].median() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "availability_365_list = df['availability_365'].value_counts().index.tolist() \n",
    "df.loc[df['availability_365'].isin(availability_365_list) == False, 'availability_365'] = df['availability_365'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "first_review_list = df['first_review'].value_counts().index.tolist() \n",
    "df.loc[df['first_review'].isin(first_review_list) == False, 'first_review'] = df['first_review'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "last_review_list = df['last_review'].value_counts().index.tolist() \n",
    "df.loc[df['last_review'].isin(last_review_list) == False, 'last_review'] = df['last_review'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_rating_list = df['review_scores_rating'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_rating'].isin(review_scores_rating_list) == False, 'review_scores_rating'] = df['review_scores_rating'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_accuracy_list = df['review_scores_accuracy'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_accuracy'].isin(review_scores_accuracy_list) == False, 'review_scores_accuracy'] = df['review_scores_accuracy'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_cleanliness_list = df['review_scores_cleanliness'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_cleanliness'].isin(review_scores_cleanliness_list) == False, 'review_scores_cleanliness'] = df['review_scores_cleanliness'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_checkin_list = df['review_scores_checkin'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_checkin'].isin(review_scores_checkin_list) == False, 'review_scores_checkin'] = df['review_scores_checkin'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_communication_list = df['review_scores_communication'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_communication'].isin(review_scores_communication_list) == False, 'review_scores_communication'] = df['review_scores_communication'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_location_list = df['review_scores_location'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_location'].isin(review_scores_location_list) == False, 'review_scores_location'] = df['review_scores_location'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "review_scores_value_list = df['review_scores_value'].value_counts().index.tolist() \n",
    "df.loc[df['review_scores_value'].isin(review_scores_value_list) == False, 'review_scores_value'] = df['review_scores_value'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n",
    "reviews_per_month_list = df['reviews_per_month'].value_counts().index.tolist() \n",
    "df.loc[df['reviews_per_month'].isin(reviews_per_month_list) == False, 'reviews_per_month'] = df['reviews_per_month'].mean() # fill na with most frequent values, fillna() didn't work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb16b1d-f4f1-438e-a5af-ae9cc3c04467",
   "metadata": {},
   "source": [
    "`(Task 2, Question 3 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c14ab6-aff9-4fcd-ab7b-34f0b77f8caa",
   "metadata": {},
   "source": [
    "**Task 2, Question 4**: Encode all categorical variables appropriately as discussed in class. \n",
    "\n",
    "\n",
    "Where a categorical feature contains more than 5 unique values, map the features into 5 most frequent values + 'other' and then encode appropriately. For instance, you could group then map `property_type` into 5 basic types + 'other': [entire rental unit, private room, entire room, entire towehouse, shared room, other] and then encode.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91f4448-8574-4397-a636-d83bbde885e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 4 Code Here\n",
    "df[\"source\"] = ord_enc.fit_transform(df[[\"source\"]])\n",
    "\n",
    "df['host_name'].value_counts()[:5].sort_values(ascending=False) # get 5 most frequent names, the rest change to 'other'\n",
    "host_name_list = df['host_name'].value_counts()[:5].index.tolist() # get list of 5 most frequent names\n",
    "df.loc[df['host_name'].isin(host_name_list) == False, 'host_name'] = 'other name'\n",
    "dummy_host_name = pd.get_dummies(df['host_name']) # Get dummy for host_name\n",
    "df = pd.concat([df, dummy_host_name], axis = 1)\n",
    "df.drop('host_name', axis = 1,inplace = True)\n",
    "\n",
    "dummy_country = pd.get_dummies(df['Country']) # create dummy for country\n",
    "df = pd.concat([df,dummy_country], axis = 1)\n",
    "\n",
    "df['City'].value_counts()[:5].sort_values(ascending=False) # get 5 most frequent City, the rest change to 'Other city'\n",
    "host_city_list = df['City'].value_counts()[:5].index.tolist() # get list of 5 most frequent names\n",
    "df.loc[df['City'].isin(host_city_list) == False, 'City'] = 'Other City'\n",
    "dummy_city = pd.get_dummies(df['City']) #Create dummy for city\n",
    "df = pd.concat([df, dummy_city], axis = 1)\n",
    "\n",
    "enc = OrdinalEncoder(categories=[['within an hour', 'within a few hours', 'within a day', 'a few days or more']])\n",
    "df[\"host_response_time\"] = ord_enc.fit_transform(df[[\"host_response_time\"]])\n",
    "df['host_response_time'].fillna(df['host_response_time'].mode()[0], inplace = True) # replace NA with the most frequent value ' unknown respond'\n",
    "\n",
    "dummy_superhost = pd.get_dummies(df['host_is_superhost'])\n",
    "dummy_superhost.rename(columns={'t': 'Superhost', 'f': 'Not Superhost'},inplace = True)\n",
    "df = pd.concat([df, dummy_superhost], axis = 1)\n",
    "\n",
    "df['host_neighbourhood'].value_counts()[:5].sort_values(ascending=False) \n",
    "host_neighbourhood_list = df['host_neighbourhood'].value_counts()[:5].index.tolist() \n",
    "df.loc[df['host_neighbourhood'].isin(host_neighbourhood_list) == False, 'host_neighbourhood'] = 'Other Neighbourhood'\n",
    "dummy_host_neighbourhood = pd.get_dummies(df['host_neighbourhood'])\n",
    "df = pd.concat([df, dummy_host_neighbourhood], axis = 1)\n",
    "\n",
    "dummy_host_has_profile_pic = pd.get_dummies(df['host_has_profile_pic'])\n",
    "dummy_host_has_profile_pic.rename(columns={'t': 'Has profile pic', 'f': 'No profile pic'},inplace = True)\n",
    "df = pd.concat([df, dummy_host_has_profile_pic], axis = 1)\n",
    "\n",
    "dummy_host_identity_verified = pd.get_dummies(df['host_identity_verified'])\n",
    "dummy_host_identity_verified.rename(columns={'t': 'Host Verified', 'f': 'Host not Verified'},inplace = True)\n",
    "df = pd.concat([df, dummy_host_identity_verified], axis = 1)\n",
    "\n",
    "df['Neighbour'].value_counts()[:5].sort_values(ascending=False) # get 5 most neighbour\n",
    "host_Neighbour_list = df['Neighbour'].value_counts()[:5].index.tolist() \n",
    "df.loc[df['Neighbour'].isin(host_Neighbour_list) == False, 'Neighbour'] = 'Other Neighbour'\n",
    "dummy_Neighbour = pd.get_dummies(df['Neighbour'])\n",
    "df = pd.concat([df, dummy_Neighbour], axis = 1)\n",
    "\n",
    "df['property_type'].value_counts()[:5].sort_values(ascending=False) # get 5 most neighbour\n",
    "host_property_type_list = df['property_type'].value_counts()[:5].index.tolist() \n",
    "df.loc[df['property_type'].isin(host_property_type_list) == False, 'property_type'] = 'Other property_type'\n",
    "dummy_property_type = pd.get_dummies(df['property_type'])\n",
    "df = pd.concat([df, dummy_property_type], axis = 1)\n",
    "\n",
    "dummy_room_type = pd.get_dummies(df['room_type'])\n",
    "df = pd.concat([df, dummy_room_type], axis = 1)\n",
    "\n",
    "dummy_has_availability = pd.get_dummies(df['has_availability'])\n",
    "dummy_has_availability.rename(columns={'t': 'has_availability_yes', 'f': 'has_availability_no'},inplace = True)\n",
    "df = pd.concat([df, dummy_has_availability], axis = 1)\n",
    "\n",
    "dummy_instant_bookable = pd.get_dummies(df['instant_bookable'])\n",
    "dummy_instant_bookable.rename(columns={'t': 'instant_bookable_yes', 'f': 'instant_bookable_no'},inplace = True)\n",
    "df = pd.concat([df, dummy_instant_bookable], axis = 1)\n",
    "df.drop('instant_bookable', axis = 1,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad3f20-7549-4b9e-8894-818c976d1457",
   "metadata": {},
   "source": [
    "`(Task 2, Question 4 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d695347",
   "metadata": {},
   "source": [
    "**Task 2, Question 5**: Perform any other actions you think need to be done on the data before constructing predictive models, and clearly explain what you have done.   \n",
    "(1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a238a3-5432-4058-8b6e-1172c4e396ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 5 Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a081c-cdc4-4fc8-9bd7-52bfd4c3e6dd",
   "metadata": {},
   "source": [
    "`(Task 2, Question 5 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16475c",
   "metadata": {},
   "source": [
    "**Task 2, Question 6**: Perform exploratory data analysis to measure the relationship between the features and the target and write up your findings. \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1509b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 6 Code Here\n",
    "\n",
    "# X list contains features to fit\n",
    "X_list = []\n",
    "X_list.extend(['source', 'Other Country', 'Australia'])\n",
    "X_list.extend(dummy_host_name.columns)\n",
    "X_list.append('host_since')\n",
    "X_list.extend(dummy_city.columns)\n",
    "X_list.append('host_response_time')\n",
    "X_list.append('host_response_rate')\n",
    "X_list.append('host_acceptance_rate')\n",
    "X_list.extend(dummy_superhost.columns)\n",
    "X_list.extend(dummy_host_neighbourhood.columns)\n",
    "X_list.append('host_listings_count')\n",
    "X_list.extend(dummy_host_verifications.columns)\n",
    "X_list.extend(dummy_host_has_profile_pic.columns)\n",
    "X_list.extend(dummy_host_identity_verified.columns)\n",
    "X_list.extend(dummy_Neighbour.columns)\n",
    "X_list.extend(dummy_property_type.columns)\n",
    "X_list.extend(dummy_room_type.columns)\n",
    "X_list.append('accommodates')\n",
    "X_list.append('bathrooms')\n",
    "X_list.append('bedrooms')\n",
    "X_list.append('beds')\n",
    "X_list.append('minimum_nights')\n",
    "X_list.append('maximum_nights')\n",
    "X_list.append('minimum_minimum_nights')\n",
    "X_list.append('minimum_minimum_nights')\n",
    "X_list.append('minimum_maximum_nights')\n",
    "X_list.append('maximum_maximum_nights')\n",
    "X_list.append('minimum_nights_avg_ntm')\n",
    "X_list.append('maximum_nights_avg_ntm')\n",
    "X_list.append('has_availability_yes')\n",
    "X_list.append('has_availability_no')\n",
    "X_list.append('availability_30')\n",
    "X_list.append('availability_60')\n",
    "X_list.append('availability_90')\n",
    "X_list.append('availability_365')\n",
    "X_list.append('number_of_reviews')\n",
    "X_list.append('number_of_reviews_ltm')\n",
    "X_list.append('number_of_reviews_l30d')\n",
    "X_list.append('first_review')\n",
    "X_list.append('last_review')\n",
    "X_list.append('review_scores_rating')\n",
    "X_list.append('review_scores_accuracy')\n",
    "X_list.append('review_scores_cleanliness')\n",
    "X_list.append('review_scores_checkins')\n",
    "X_list.append('review_scores_communication')\n",
    "X_list.append('review_scores_location')\n",
    "X_list.append('review_scores_value')\n",
    "X_list.append('instant_bookable_yes')\n",
    "X_list.append('instant_bookable_no')\n",
    "X_list.append('calculated_host_listings_count')\n",
    "X_list.append('calculated_host_listings_count_entire_homes')\n",
    "X_list.append('calculated_host_listings_count_private_rooms')\n",
    "X_list.append('calculated_host_listings_count_shared_rooms')\n",
    "X_list.append('reviews_per_month')\n",
    "X_list = list(set(X_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc4f1af-f2cd-46c8-8c05-a620333feff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between \"price\" and other features\n",
      "                           price\n",
      "price                   1.000000\n",
      "has_availability_no     0.166959\n",
      "bedrooms                0.077317\n",
      "accommodates            0.076764\n",
      "bathrooms               0.068749\n",
      "availability_30         0.067838\n",
      "beds                    0.067718\n",
      "availability_60         0.056399\n",
      "availability_90         0.048513\n",
      "minimum_minimum_nights  0.041300\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test dataset\n",
    "df_train = df[df['type'] == \"train\"]\n",
    "df_test = df[df['type'] == \"test\"]\n",
    "\n",
    "# split into X and y\n",
    "X_train = df_train[df_train.columns[df_train.columns.isin(X_list)]]\n",
    "y_train = df_train['price']\n",
    "X_test = df_test[df_test.columns[df_test.columns.isin(X_list)]]\n",
    "\n",
    "\n",
    "y_list = X_list.copy()\n",
    "y_list.append('price')\n",
    "result = df_train[df_train.columns[df_train.columns.isin(y_list)]]\n",
    "result['price'] = result['price'].astype('float')\n",
    "correlation = pd.DataFrame(result.corr()['price'])\n",
    "print('Correlation between \"price\" and other features')\n",
    "print(correlation.sort_values('price',ascending=False)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf6ed4-8fed-4f0c-8e06-d0e95ae480d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a965eb-e661-4772-af72-98f19e1bae41",
   "metadata": {},
   "source": [
    "`(Task 2, Question 6 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f6968-d9c2-422f-9935-eba856b3c028",
   "metadata": {},
   "source": [
    "--- \n",
    "## Task 3: Fit and tune a forecasting model/Submit predictions/Report score and ranking {-}\n",
    "\n",
    "Make sure you **clearly explain each step** you do, both in text and on the recoded video.\n",
    "\n",
    "1. Build a machine learning (ML) regression model taking into account the outcomes of Tasks 1 & 2 (Explain carefully)\n",
    "2. Fit the model and tune hyperparameters via cross-validation: make sure you comment and explain each step clearly\n",
    "3. Create predictions using the test dataset and submit your predictions on Kaggle's competition page\n",
    "4. Provide Kaggle ranking and **score** (screenshot your best submission) and Comment\n",
    "5. Make sure your Python code works, so that a marker that can replicate your all of your results and obtain the same RMSE from Kaggle\n",
    "\n",
    "- Hint: to perform well you will need to iterate Task 3, building and tuning various models in order to find the best one.\n",
    "\n",
    "Total Marks: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3358bbf",
   "metadata": {},
   "source": [
    "Ans: As we can see from the dataset, we couldnt find many features that are correlated with price to a big degree, so we will use the whole dataset as all attributes are somehow related to price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b3bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale features\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(X_train)\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb53af94-d769-4a1d-a4a1-433f3dc7b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE linear scaled: 1285.009\n",
      "Training MSE linear: 1283.256\n"
     ]
    }
   ],
   "source": [
    "#Task 3 code here\n",
    "\n",
    "# Starting off with Linear Regression Model\n",
    "lr_s = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "y_lr_train_scaled_pred = lr_s.predict(X_train_scaled)\n",
    "y_lr_test_scaled_pred = lr_s.predict(X_test_scaled)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_lr_train_pred = lr.predict(X_train)\n",
    "y_lr_test_pred = lr.predict(X_test)\n",
    "\n",
    "print(f'Training MSE linear scaled: {mean_squared_error(y_train, y_lr_train_scaled_pred,squared = False):.3f}')\n",
    "print(f'Training MSE linear: {mean_squared_error(y_train, y_lr_train_pred,squared = False):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a1ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE lasso scaled: 1283.299\n",
      "Training MSE lasso: 1283.408\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "    \n",
    "lasso = Lasso(alpha=0.1) # alpha = lambda (above)\n",
    "\n",
    "ls_s = lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_lasso_train_scaled_pred = ls_s.predict(X_train_scaled)\n",
    "y_lasso_test_scaled_pred = ls_s.predict(X_test_scaled)\n",
    "\n",
    "ls = lasso.fit(X_train, y_train)\n",
    "\n",
    "y_lasso_train_pred = ls.predict(X_train)\n",
    "y_lasso_test_pred = ls.predict(X_test)\n",
    "\n",
    "print(f'Training MSE lasso scaled: {mean_squared_error(y_train, y_lasso_train_scaled_pred,squared = False):.3f}')\n",
    "print(f'Training MSE lasso: {mean_squared_error(y_train, y_lasso_train_pred,squared = False):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0820e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE ransac scaled: 13435382072119.688\n",
      "Training MSE ransac: 4864184.265\n"
     ]
    }
   ],
   "source": [
    "#RANSAC\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "ransac = RANSACRegressor(LinearRegression(), \n",
    "                         max_trials=100, \n",
    "                         min_samples=50, \n",
    "                         residual_threshold=2.0,   # example an inlier if distance from the fitted line within 5 units\n",
    "                         random_state=1)\n",
    "\n",
    "rs_s = ransac.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_ransac_train_scaled_pred = rs_s.predict(X_train_scaled)\n",
    "y_ransac_test_scaled_pred = rs_s.predict(X_test_scaled)\n",
    "\n",
    "rs = ransac.fit(X_train, y_train)\n",
    "y_ransac_train_pred = rs.predict(X_train)\n",
    "y_ransac_test_pred = rs.predict(X_test)\n",
    "\n",
    "print(f'Training MSE ransac scaled: {mean_squared_error(y_train, y_ransac_train_scaled_pred,squared = False):.3f}')\n",
    "print(f'Training MSE ransac: {mean_squared_error(y_train, y_ransac_train_pred,squared = False):.3f}')\n",
    "\n",
    "#results mean that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "217bfdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE random forest scaled: 497.126\n",
      "Training MSE random forest: 493.925\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=1000,\n",
    "                               criterion='mse', \n",
    "                               n_jobs=-1)\n",
    "fr = forest.fit(X_train, y_train)\n",
    "\n",
    "y_fr_train_pred = fr.predict(X_train)\n",
    "y_fr_test_pred = fr.predict(X_test)\n",
    "\n",
    "fr_s = forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_fr_train_scaled_pred = fr_s.predict(X_train_scaled)\n",
    "y_fr_test_scaled_pred = fr_s.predict(X_test_scaled)\n",
    "\n",
    "print(f'Training MSE random forest scaled: {mean_squared_error(y_train, y_fr_train_scaled_pred,squared = False):.3f}')\n",
    "print(f'Training MSE random forest: {mean_squared_error(y_train, y_fr_train_pred,squared = False):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70286834",
   "metadata": {},
   "source": [
    "Performance increases, which means more catergorical data in our dataset.\n",
    "Random forest performs better with categorical data than linear regression or Lasso\n",
    "This also performs well because doing variable selection is not that important in Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ddfc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE bagging scaled: 608.642\n",
      "Training MSE bagging: 643.230\n"
     ]
    }
   ],
   "source": [
    "# BaggingRegressor\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagging = BaggingRegressor(n_jobs=-1)\n",
    "bg = bagging.fit(X_train, y_train)\n",
    "\n",
    "y_bg_train_pred = bg.predict(X_train)\n",
    "y_bg_test_pred = bg.predict(X_test)\n",
    "\n",
    "bg_s = bagging.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_bg_train_scaled_pred = bg_s.predict(X_train_scaled)\n",
    "y_bg_test_scaled_pred = bg_s.predict(X_test_scaled)\n",
    "\n",
    "print(f'Training MSE bagging scaled: {mean_squared_error(y_train, y_bg_train_scaled_pred,squared = False):.3f}')\n",
    "print(f'Training MSE bagging: {mean_squared_error(y_train, y_bg_train_pred,squared = False):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ae02a",
   "metadata": {},
   "source": [
    "In Random forests, only a subset of features are selected at random out of the total and the best split feature from the subset is used to split each node in a tree, \n",
    "However, in bagging all features are considered for splitting a node, that means some of our features need to be eliminated.\n",
    "As we have not eliminated any features, Random Forest works better than Bagging Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44933a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE AdaBoost scaled: 451.436\n",
      "Training MSE AdaBoost: 421.051\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "AdaBoost = AdaBoostRegressor()\n",
    "ada = AdaBoost.fit(X_train, y_train)\n",
    "\n",
    "y_ada_train_pred = ada.predict(X_train)\n",
    "y_ada_test_pred = ada.predict(X_test)\n",
    "\n",
    "ada_s = AdaBoost.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_ada_train_scaled_pred = ada_s.predict(X_train_scaled)\n",
    "y_ada_test_scaled_pred = ada_s.predict(X_test_scaled)\n",
    "\n",
    "print(f'Training MSE AdaBoost scaled: {mean_squared_error(y_train, y_ada_train_scaled_pred,squared = False):.3f}')\n",
    "print(f'Training MSE AdaBoost: {mean_squared_error(y_train, y_ada_train_pred,squared = False):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4147c9f",
   "metadata": {},
   "source": [
    "At this point, we predicted using Random Forest and it gave us better results\n",
    "That is because it efficiently manages a higher-dimension data set.\n",
    "It handles missing quantities and maintains high accuracy for missing data unlike AdaBoost, which is prone to overfitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0fde2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE linear: 1283.256, quadratic: 1233.111\n"
     ]
    }
   ],
   "source": [
    "#Doing polynomial with quadratic features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "X_quad = quadratic.fit_transform(X_train, y_train)\n",
    "\n",
    "X_quad\n",
    "\n",
    "lr_1 = LinearRegression()\n",
    "lr_2 = LinearRegression()\n",
    "\n",
    "# ----- fit linear features\n",
    "lr_1.fit(X_train, y_train)\n",
    "y_lin_fit = lr_1.predict(X_train)\n",
    "\n",
    "# ----- fit quadratic features\n",
    "lr_2.fit(X_quad, y_train)\n",
    "y_quad_fit = lr_2.predict(X_quad)\n",
    "\n",
    "y_lin_pred = lr_1.predict(X_train)\n",
    "\n",
    "y_quad_pred = lr_2.predict(X_quad)\n",
    "\n",
    "print(f'Training MSE linear: {mean_squared_error(y_train, y_lin_pred, squared = False):.3f}, quadratic: {mean_squared_error(y_train, y_quad_pred, squared = False):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95eac80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MSE train: 1283.278\n"
     ]
    }
   ],
   "source": [
    "#Cross validating using Ridge Regression\n",
    "\n",
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "ridge = Ridge(alpha=0.1)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_ridge = ridge.predict(X_train)\n",
    "y_test_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "print(f'Ridge MSE train: {mean_squared_error(y_train, y_train_pred_ridge,squared = False):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be0c32e4-8dc8-4849-997d-f1b4be125d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = make_pipeline(StandardScaler(),\n",
    "                         SVC(random_state=1, probability=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8120bd8-0c9f-4c30-9594-89d67bace0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]  # range of values for C and gamma\n",
    "\n",
    "\n",
    "param_grid = [{'svc__C': param_range,   # range of values for all parameters\n",
    "               'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, \n",
    "               'svc__gamma': param_range, \n",
    "               'svc__kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a486683-2512-4be5-b307-2609c9b31f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04557142857142857\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator=pipe_svc,      # initialise gs object\n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  refit=True,              # this will refit the best estimator to the whole dataset automatically\n",
    "                  cv=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "\n",
    "gs = gs.fit(X_train, y_train)            # fit gs\n",
    "\n",
    "print(gs.best_score_)\n",
    "\n",
    "print(gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1906b8ed-3967-454d-8fc2-f5355edff48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc2 = make_pipeline(StandardScaler(),\n",
    "                          SVC(C=10.0, gamma=0.01, probability=True, random_state=1, kernel='rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a6bfaf9-fd0b-4bc1-a1cf-e45e21bb3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svc2 = pipe_svc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63180f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['65.00', '146.00', '150.00', ..., '80.00', '100.00', '350.00'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72adf0f0-3fef-45c1-8fcf-bef49cb439eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit= pd.read_csv('sample_submission.csv')\n",
    "df_submit['price']= y_pred_svc2\n",
    "df_submit.to_csv('submissionSVC.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1010e5-03e6-475b-a9f8-51b19cb556d2",
   "metadata": {},
   "source": [
    "`(Task 3 - insert more cells as required)`"
   ]
  },
  {
   "attachments": {
    "Capture.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABHMAAAA4CAYAAAB+BbTLAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAAhdEVYdENyZWF0aW9uIFRpbWUAMjAyMjoxMTowNCAxODowMzozN/N0sBgAAB/tSURBVHhe7d0JgE1l/wfw3+ybJoSpeP9aZGl5I6KsKeEtlWWktIss9bZSItlS3lKihJQklXWsJSK8vUSIlKVQWUpSxj7rnf7n+zvnuXPunTtj7izFzPfTe96z3Oeec+a695zn/M7veU7InxYJAIsxhISESFZWlj2P5WbamsGSELu4ymVVREREREREREQlHmIoBiIkIfjPWoTlIaGhGkPBdKg1bWIu7vfkV8BgjnuRN5BjDR6PxzvOcpZZ/+eUJCIiIiIiIiIi5QRqQq0hLCxMp81Yl4eGOgXtAE8wcgRzzCz+32ThIKDjsYbMjAz55ptv5a23J8ry5Su8ZVevWSMJFcvrNBERERERERER+dp/4KDEnxErYaGhGsjRoI6TrQPBBHSyw0AuGqSxBowxIJCTkZ4hm775Vu686x5Ztmy5N5BDREREREREREQnh9gKYiwm3mL9X4HiKz7BHO8KQkLsFVuT2qTKGjIy0uWtt94u0EaIiIiIiIiIiEo7xFYQY9FubKx5jbE4GTnBxFsCZuZYa7CDOVlZOotmVunp6bJixX91noiIiIiIiIiIgoPYCmIsYLq2QQwmWDmCOSYSpMEca9D+cjwea4MZ3teIiIiIiIiIiCg4iK1oCygnkOOOwQQj9z5ztKmVNW3N48lVmZ5M+0UiIiIiIiIiIgoaYiv6dHBrWuM3Tjc3wcoZzDG9J+vKnSgRpguwciIiIiIiIiIisrljLPgP08rEYvIpRzDH/Xaddjbi+woREREREREREQXHycSxhhzxlyCEWCvRMJAzUmi7ZfrKyczMlLS0NDmYfEhatmztlPC1es0aSahY3pkjIqLSKjPTIxnWeUNTR60B55KrdrwotaLPlsoRZaVKZDlpFF9NLi1TWc4Mi3He9dfh/hERERHR32X/gYNy5HCylC9XVqKioiQ8PFzCwsIkNDRUByMkH1k6+QzmpMvBQ8nS8noGc4iIyBfOH6nWeQJBiEAu+X6IM5UtPixa7il/tfSp0ipfJ6vC4P4RERER0alAgzlHkqV82XISFRVZPMEcBHLMwGAOEREFkpaeYQ3pzpxYJ6NQicBJyTkh4UR02JMim0/8LLtTD8qetIPyyeEt8n3afi2PbJNHEq6T2yvV1/mixv0jIiIiolOFfzAHgRwzFEkwBwEcd0CHwRwiIvJ37ESKnisAAYho64SUnxMPrDq6Q0b8vFjWntil8zWjEmRmzZ5F2nSI+0dEREREp5LcgjkI5GBsMJhDRERFDucHBCIAJ57Y6CjvnQQ0zU1NTZX09HTJyMjwBivwekREhERGRkp0dLSmlMLKI9vl2d3z5fv0/RqQmF69u5SLiNPXCor7V7j9IyIiIqLiwWAOERH9bY4cO65jNAmKi7EzQRCEOHbsmJw4cULncQJyn1fAvSw2NlbKlCmjQQk0I2q/baw2HSqKDBPuHzN0iIiIiE5FRRnMyW6URUREdBImo8QdiEAA4sCBAzrGiccEHTA2JyhMmywTTLvfg8BDUs2eUj0qQbal7ZfEbWO1XEFw/wq3f0RERER0emAwh4iI8gUd9SKggDsHJhCBbJLDhw97gw8YY0CTIGR2Hj16VI4fP67vQ/Mgd6ACY7wX6/AGJCLtgMT7+1fr+oPB/Svc/hERERHR6YPBHCIiOikEDvDkJUAfL4CsEAQb3MEFwPSePXvkhx9+0EDEb7/9JuvWrZMNGzZoUMIdkACsw2SYDPm/m3TZa78t864vP7h/hds/IiIiIjq9MJhDREQnlZpmPz4bT11CZgn6eDl06JBPIAIDOuj99ddfJSEhQRo0aCBVq1bVvl2qV6+u71m1apW+35THAMgwweuN4i+SK2Orys8Zh4LKLuH+FW7/iIiIiOj0wmAOERGdVEZmpo7x+GxANgiCEBhMtkhUVJTs3LlTs0gQXPjxxx9l6tSpsmTJEg1clC9fXn755RfZu3evlkUgAu8z0FwIelduqePXDyzXzn3zg/tXuP0jIiIiotNL2CCLM+1l7vaZAe32U1JT5b33pjglfHXt1k3KxNnt/0ualJQUTXFH/wUYSis8Ihd3i3EB4h7i4+OdErZff92vFyH+n9eRI0fk999/1zvHMU5fEYDP99tvN8ta6+KlYsUKPq+5mfUG2qbb99u3y6efLpFy5crlWu7gwYOycuUqa31HpEKFs7Rz0UCwzc+WLZeQ0BA566yznKW+cvu7/Jly/p+fGU6cSNG776eKn3/+WfcLf1Nunw+VHpmZHg1GoNPeSOt3je87vtM4PwACC3iU9rZt26RSpUpSo0YNmT59uv4Gy5Ytq09cuvjii/U4snXrVg1eoExaWpo3GIGx+R1Vjakg6VbZm+Mvl8tiK2smSl64f4XbPyIqHVDn+nLtWm3GWbFCBZ96moHjzKZN38gPP/6Qaxkcvz7//H8nrUcZpnymdT2RW30K9bcNGzZa66ugx0R/ua3D1NP961WB6jDYxspVX+RZ36Tigbr3p0uWyplnnhmwvpuf711pcLLPCXL7reA3kpx86JS6nqDAjlvXfWlpqRITHWPV8eynWGFAXc5dZzN1vLzw0eQn0e2BHrLE+lG9POJFad++nbO09NmyZavc2OZmZy4bDraPPPJvebBXT51v2qy5VUnYm+Pzev6F/8iECW9J82uukYkTJ+iyZ58dJB98OFW/Y0atWjXlvcmTfE7UCOLUrlPPmROZMWOq1Ktb15mzbfrmG7n33i56EDPKlSsrM2dMkwsuuMBZIvL4E31k9uw5zpy9/6NHvyqtW9l3sgEnlE63ddYDpYF1TZo0Uf552WU6jzIvjXjF+lve0f13/12BmL8/N//4RxX574plztzf57vvvpP7u3bXYA58tGCedRFZS6ep9EpJTdNgBLJKEIxABggqDYCTzq5du7TijPPI+eefr+NZs2ZJs2bN5DLrN4PfCH5r6Ndl5cqVsmPHDmnbtq3ExcXpa+4T1xlnnKEVEQQj0DQJzZJinD5mcsP9K9z+EVHJ98mixfLww49ax41YnT9+/ESO+g/66Urs2Mmq42TqBcbRo8fk9ddH+5QZ88ZYGTlylF5sIggdERHuUz/y5y6PwEuVKpW1boFjGvzxxx9yfcvWuk00M0Wd77HHHvHWK+Gll16WN8aO0+xErOPM+HhZsGCu1hWTkmbLE72fdEr6MnUYbOOWth30QhlBHGzj5ptvkldefskpScXJ1PfxHcC5rmbNmjJr5jTvdwB1+MTEThqYyO17VxrgmnPFiv/qeRyf06WXXiLTpn7g81vx/x6/+J8XvNdbuNb45JNPTonrCcobH03+F1m69DNZs+ZLzfKgbC1bXq8D7gwjqDFixCsa7AnGlPc/kPemvK/TrVq2lG7dumrAZOvWbdKnT19dbsyePdeZss2bO9+ZynbnnfdoIKdFi+tk1KiR0qBBfZ2/9777nRJ2ZQCBHBwUH33kYS2L/X/ooYd99r/Xg//WQA72p3//p/ViCuvCNnDghAZXNcwzOOMPB2TzuWEaYmNjvMuaN2+uy/5Ob098R1r/q41mYBG5Zf1pPxI7zAkaICMEAQdkjKDyX7FiRWnatKkeK1HRRkaJqXQnJydrhR8DKiIog2ADmhLh6UxYDwYD5cBsy2w7L9y/wu0fEZVsqLugrjP8hWGy4at1OvTp84ReZLuhzpSYmCjfbNqgZYYMHiRPPNFb60qwbv16DcwkJc2Q9evWaLlrr71Wnn9+uL7uD3Ur1BFxQYryX29cr5mKzw4c7JQQedDar9qX19Z1oQzWjfegSSmgLj7+zQl6cw6vb9m8SWrVqiU9ejyor+NC9scftvsMuKGIC+KLLqqmZbCN6hddpO/FOj7/fLnMmzdf/x4qXgi2zZk7T9asXun9Dhw6lKxBPsB3C/Xru+68w/u9Q4AC31ec80oLXBfhmvOLVZ/r57T52681o/9N17UGro/OP/88/QxRBp/Tk089Xao+J8rJru1RDji4PN3vGRn23BCr4hznLCUYP+4NHT5ZuEAvLADNA4Lx2VI7anzP3XfJuHFjpN/TT8mU9ybrBczmLZv1NWPGzJk6vuKKOjrG3SW37dt3aAQb3hjzmtx8UxsZ8/ponUeWkDHp3Xd1jMoMsokmvDlOM3xwZ3vc+Df1NVQekIkF2J+u93fRuwe42MI2cLCFY8eOW9+NodKly306fzLYJ/O53XfvPboMd5TMssGDntVlyIx57PHeUrdeA7n7nvt03g0XdwMGDJQW17eSm25uK6+OGu2tZKGpWvcevazP801NRcbrHW+9XS8WcaBHxadR42b6nkD27/9N6tSprZUcIresLDtYYDJA0JwHdwvw28HTlpDJNXbsWM0aSUpKkr59+8rmzZv1u7dlyxY9PqCfF3xXEYhITU3VoCEyQP2Z77O5G+GKU+SK+5etIPtHRCUbsvqeGzrYJ2O6UcOGcuDAAWdOZPXqNVq3QX3M6Nz5NhnwTH+9qIQycXEyetRInyychldf5Q28+MNNO9xcq1v3Cp3HzbQnn+wt8+bN03nAjcGevbo7c6LrRrYy9geWLP1Mrra2YdYBI0eO0EBMbttFPad7927ejIbEDh1k4MABOg3nnH22nHvuObJ7125nCRWXDz+cJo8/9qg34x4ZJWOsuvrFteys7/Xrv9L6dd++2dlV+J7WqV1bpk6b7iwp+XATp1fPHt7PCd/d1q1by/p1X+k8ArLLli/X6xfzvcbndOEFF+T4nMw1AK4Vpk2f4SylkorBnFwMH/6idYKpLjdZF+EU2D7rYgJNBZAOdoXrJJsfCWcn6HjGzFmyePGnegGCVFhEmtesXqWvAU7UJmvmtdGvajYLKh/mJA+484ITPyQ5TagWLPhIx6aJENaBfmnA/W9644036HjjRrtJlVnvueee630vDprXXXetTpuDKiLnqOQUJaSZ3tjmFpkzZ651kebRgzEyZXBXA3Agb3BVIw0oIfCyc+cPMmrUa9K2XQd9fc/uPfpZIvvovi5dtS8i3L1v2y5R2rVPlEWLF+vnifeYOyJu3R/oKkmzZmglh8jNZH6YAAGCEAYq4ujnBc1+cEcXGSaojKBytmzZMlm4cKF25IvAxKZNm2T37t3aPAjHDWSRIMDhziwxAQoT+AgUsPDH/Svc/hFRyXbOOefIbbd1cuZsyJZwN6NGnQMBE3NTCTeHUAbvw/sBzWNuuOFfOm0sWPCx1LYuvAPZsX2H1L3Ct3543bXNtT5m6na4mXVlveym9D/t2qU34q66qoHOI+AdEW5fvPpDIMAf6kyHDh2WB7p1dZaIdWxtL1Wr/p8zZ9e30C9isHVXCt4Gq35dv/6VMuGtt/U7hRuS6OsFWemAf18wAQq3jRu/dqZKPtz07dHjAWfOtmL5Cqlbz/6OouUCzvv+3Uw0btzIe20CuHk78tVRckfn2+WmNm2kf/8B3usIKpkYzAkAB/l3J78nr4582VlCbudfcJEODRs2kSqVK8uM6VPlvKpVnVfzp/cTjwmaMeGCBQf36jUulquubiQffDDVKWGbPcduYoUKBwIs6EMC5s7zbWo1O2mmXHLJxdK3bz/dt0GDh0qTJo01LRdM5hAyidwnjPj4M3RsUhS3ffe9js91Ki4G0nVh/2/7dWwi50WpT++n9CIP6cFIM507N0kP3MP/Y7fpRtMv3J3q1vV+TUVFmiWgQoTsJGOnddH30YK5smrV5xr8wmeMPn2QetyhQ3st8/HHC3XsVhx/E5VMCEpgQBABfRzgd4W27gggoFL/1FNPyUMPPaQBCmSh4HHay5cvl0WLFsnatWs1IIvsEgRxzbqKEvePiCgwZP5e9s86elyZ/O47zlKRPXv3yqHkQ9KufUfNRq5q1euefLKv9sPhD3UOrOfiS/6p86i3BII604UXZvdbCKYOZvoNc8MxrUuXbnrTDXU+QPBozZdr9AaiMXr06zpGeX+oM7mzctxM5jOa9Ywf/0bQdVcKDm4gol47ZOhzMmvWbKsu2kzWrlsvrVrd4K13N23aROuq7vo/rsOQeeXJzL7xUdrgd4fvvAlK4rNENpm/sPBwrecbUVHR2qwRQVhk8XTsmKgBVyq5GMwJ4NFHn9DO13hxG5jp56VevXqya/du7SwYB95g4LNFBg6aOiHogrRLZJv0f2aAdlJsmP5xzJ0gdFgHi/yaWqHTsM2bt0jlypV13xAowl2mhx95zClhQ8/hgZQt69sv0omUE86ULzQDKw44SKN3eli0+FMNcI0ZM1Y7xcKFGypO11gnwZdeHC6XXnap3tnofMfdWh7cFRoc7HG3Hxk25jt8+eV2hQvp0OA+8BOdjAkWmAwQkw2C5cj8QMABYyxDOj8yRqpUqSJt2rSR+vXrC57E1KpVK00ZrlatmpZHoDJQ1oh/RomZzwv3L1tB9o+ISo8+vR+X/v36avbKfV26eesPx44e0yyKjz+er02tMMycOU37B0Qdxa1SpYq6nscff1Q2fr0x1w6I8xLrdMTs1r17Lx27g0PoBLdhw4bSrNm12vz8muYt5PP//c8b7HFD5jIC3e6sHLfEDu11vxs1vNq60H086LorBQffMUD2KbpmQIABY9RJBw95Tl9D0G3okMHy7MBB3u4BbrvtDs04Ka2QSYMHrEyZ8m7AoKS/6JhoZ0q0axD3e8zNaCq5WMvzg+YnWR6PtL3lZu3HAIPHkyUHk5O193DK7jNnxvQPNdMDFYHXXhvjvGrDk1vcPH7z+FzxKMlmzZrqnSF0Sjd8+PP6GpoJoUkRUm1NgAOd4SHjpmdPu8M7dAqKTvEAJ2+7w+JysuyzT3XfEChCpB/936AcUoMBqb2mE2M4csQOaphH+9WsUV3H+/b5dgJsgh/ocLQ4mBMerFu33jtER8d4A0hffLFarqhb36qAPCYLPrKbkRH9FUJD7WCECRCgomACFBibaUDwAPPo5BdPbbrwwgs1OIHfEH7zCFYg2IjmQlif+71gKiEm8OH3ckDcv2wF2T8iKj1wQY0B9aWdO3fI/PkLdHm1i6ppPyXubBX0X4OgibtpO+CpRFgH+hVMSpqp6zDNptwSKiV4M54NUwfDI3ndhg4dpvU+1C3NcczAjT80A7/hX61l2LAhsnjRQu1EFw+ocEPGTm5ZOdCoUUPd77Fjx2iw4NWRgfsQpKJhmvF1vt23W4I2bW70dm8A6Pvlq/VfatOgu+66Q7tcQJ0eT7gtbdB0sO/T/eWdiW/59E2F36G7H1ADdYPiujah0wODOX7Q7hDZJo2bXOMdcEdi2LAXpHfv7E7hyIYLCzCpkKbd9PjxE7x3e9Bp73ynDxtUFuDWTp31szV93ID7oI02tOg7BpDua7KBMJydYPe3Y5pa7ftln47d0WiMkWoIqDjghIITA7ifjmU6V25sneDB9I2DYJGpvODv+OgjO0URwafigP3DnXZYvOhjPZFh+PDDKTJvbpKcd15VmfjOJE1X7devrzbD+uD9yVqeqLiFhtinCo8TjEDTIH/+QQl8nxFQwO+ubNmyGqTA7xpBii+//FLHpoybWbfZltl2Xrh/2Qqyf0RUsqFp9cBBQ5w5G+pJyN41zZdwMwvNtN1Q/9m/f783C+attyfqQxbcTPBn3z67LuZW54o62u+HG+qDOK6ZJ00BmpSgD0UEcvyz4ufNXyAvvjhCnwSKQAw6bkb9DHU89zpyy8pBEBzZzv7ZRch+NE3nqfigT8tt23wf5oE+HxHoA/y74N8H5zL8+6LvGDzpEf/GyNwvTZAphtYOeFCL/9+O/qxwzvd/CAxuWOM3QaUXa3l+Jk6ckOMRhzgQIeUTr5Hd3tq0uV648BNdhjav0KP7A3qwQYedl9euq+UwRlMhpPqhk11A5hOgjxv0to60ysREu3M+0z+O6bALHQ2bbCAMeJwmLF1qP3UKnRhjm4hYt+/QUaZOnaYdByMgg+UmAHP//faTp54b9rym6qIM7iShDNqVAu42mQ6SUQYnmObXXq+RbwSVOt3aUV8rDmjXCm3a3KIVJrTpRrtitF9HpQtN0QAHbvyN6OSY6K8QYVWswGTcnewuEIISqJghcwRZbybzDU9iQrAB2SYYUGHzD0aYdadn2Nsy284L9y9bQfaPiEq2SgmVZPLk97QTWgPTv/yyz/sgCNR90IQTT3JFEAc34tDsCdnBpjNiHF9GvPyKPlUHUA7lUb9DPRDzeHKmueBEnQ8BIrNdBI4QmLndumg38LSd999/XxYt+jhg9wbVrGPd2HHjvdvEOvr1H+Ct0xm5ZeWgiQ+yt9GEH38ToJNn1KP8O3Omotep063yyshXvU9nxeO30YTolrb2dQDq+1u3bpWhzz2v3x8MeHR9xYoVvN+70gDfa9T7hwwe5PPUOQPfa1wn4PdjArDIZkMAs127W3SeSicGcyhoaG6GAU0AcHGBR3Tfe6/dfwsCMeh4Cx3n4aSJcjgwY37O7JneEzUCMt26ddWDEyL0eOoSyl15ZT272dWWrd50wrZtfQ9SqHAgAIMmU6gwuLeJEzYqFjhpYB5ZLmabD/bqqdsE9KeDMuhbB+91VyAQuEMbbewPng6FJmHoiwcdEvtXEorSkMEDrQNyWznw+++aCbZy1Sr9G7BdGPjsM/oEAJwI8TciuGOe4kVUnMLD7awxNDlF8ABBBBNczI3JNEE2GcrjUdqA3xoCEoGaCGGdJkCB18FsOy/cP1tB94+ISjY8AQdPBB05cpQ2Wccwduw4bcphMmtQv0E9DfUjPJQCnRujqfvUD6fo63DnHZ3loYd6aZAH60A5lMf78H5kay9ZulTrToDjFbZhtosHZ7RocZ33phzgph7qc3jN7BsG0/Ey6nhohm+22QRZ840aap3OmDRpcp595aAehadX4W/COvDkUGSBuNdBxQOfMT5rfOb47O+4827p0uU+/S4Zk955WzNx8H3C8PXXX/t0zl0a9O83QG8co+9Q8xvA0LRZc6eEfZ2Ap7KZ38rsOXO0Xx3ciKbSK8Sq9OltPWekUHlERRBjDGlp6XLwULK0vL61U8LX6jVrJKFi8XQMS6cvE8zBXZG8giAog7IImBRWfraJIA3SbsPCwuVs5xHpgZh14QIpvx0f4ykM5u6RP2R55YfZP9zpio+Pd5ZmM/t0sotBoqKUkpqmmSXI9IiJjtI7uMi4CwTnEwwIOiD1Hs2D9u7dqxl7+G0iMIE7vO3atdMyKIvABLLfEIzw31Z+cP8Kt39EVDqgDgF51WvMk6YC1UEMBEfQN2FeZdxQ/swz4wtVd8HNtZPVKfNi6nVFUd+k4Jmbo7nBvw3OYfn9TpVW+B4fPnwkz2sYOrXtP3DQOs4mS/myeJpppCYpYECTeowN/5t2gTCYQ1SE0JYcT4MIBE3EiE5XOEccPW73kVXGqsDjhIO7sO4Oxd1wDkHzoO3bt+t5BGV/+uknrYQjOBEXFydNmjTR7D6URb8wsbGxOn3shJ0Kf0ZcbL5OZMD9K9z+EREREVHxYzCHiIj+cmnp6daQoScbBCQAzS2RGmyYcwnGOCGhOSOyzHDHDWnwe/bs0dcQkOjYsaNmmCAggQEQ8MDrUZER1pCzo+C8cP8Kt39EREREVLyKMpjDPnOIiChfEBzAiQbB/uMpqboMQQR3e21z4kGqNIIUyCBBWjXeh5sDaAqENPs//vhDmwghndoEIpBRgkAEyhYkEMH9K9z+EREREdHpg8EcIiLKN5NRgsCCCUigeY8JMiCYgAF3FhBwQCACAYnq1atrHw3ILkGfUC1atJCEhAR9L2BdCHKA2UZBcP8Kt39EREREdHpgMysiIgoKzg+mXxZkgcRGR+kY0LEvAg4YduzYITVq1NBlaA6UlpamHWsiE8U8QQ7rQiDCnIMQiDDrKijuX+H2j4iIiIiKB/vMISKivx0CEjhXAJ6cFG2dkPJz4gGcc1KtcwueugQ4gRV1Rgn3j4iIiIhOJewzh4iI/nYIHqCjXUBQAZ3vIkCRnpEhHk+WN1AB9g2CLH0NZVDWBCKwjuIIRHD/iIiIiKikYmYOEREVin+WSH4Fm41SUNw/IiIiIjoVMDOHiIhOGTjZxERHSXyZOImNjtYgQ1hYqJ6UDPsEFaqvoQzK4j1/RSCC+0dEREREJQ0zc4iIiIiIiIiIilmxZ+bwTh8RERERERERUfErSAwm12ZWWBmDOkRERERERERERa8wcZdcgzm+/tT/ERERERERERFRAdkd3ehkYXiDOSeLBjFTh4iIiIiIiIio4PITe8mPHJk57viQTjtBnLDQEGnSpLEuJyIiIiIiIiKi4CC2ogEba8gRfwlCzmZW5qlWCOLgP4xDQyU8IkISO3SwN0pEREREREREREFBbAUxFo21WP8h9qJcTxjPj4B95mjAxloRRlhtmLWhyIhIqV6juox4+SVp3LgRgzpEREREREREREFAbAUxFkRUNKyisZfg4yshf1qcaWsd9iTGWVlZ3iEzM1MyMjLkREqKHD12TFKOp0hqWop4PFnyZ1awyUBERERERERERCVbSGiIhIWFSnRUjMTExcgZZcpIbEyMRERESHh4uISGhnoHE9DJb2AncDAHAwI51rwnM9Mb0MGQnpEh6Wnpkp6eZr2uxe33BR9IIiIiIiIiIiIqWRAicYIyodYoMjJKIqMiJdIJ4phAThjGVjltdqWlCxjMAcyaRQjiYNpjjT2ZHvF4MnU+E9NZHhS2SoXY5RnMISIiIiIiIqLSzhvM0QkJCw2T8PAwXRYWFi5h1rQ2tbLmEdQBTOc3kAMBgzk6xuAEc7S5FcYej888gjnZb2c0h4iIiIiIiIhKOztOosEZBGycoI0Gb8LCfOYLkpUDOYI54F5ksnMwmGkdW69pOVdZIiIiIiIiIiKyIFiDwZr0BnNMEMeZNoIJ5EDAYA5gMQas0BvQwXJvcMeatv5zby6XVRERERERERERlXjuoAwiJAjlYJEGcJwsHBPIMTEX93vyR+T/AW0m8/ujMxCsAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "93e835b5",
   "metadata": {},
   "source": [
    "![Capture.PNG](attachment:Capture.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8420b0e",
   "metadata": {},
   "source": [
    "In the end, we decided to go with the pipeline model coupled with StandardScaler (to standardise the data) and SVC with rbf kernel, as per the gridsearch suggestion which gave us our best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
